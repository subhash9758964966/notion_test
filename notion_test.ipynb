{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xu5vy07zuNAv"
      },
      "outputs": [],
      "source": [
        "# !unzip klimb_llm_optimization_challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "unLeT8lLufsn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"klimb_llm_optimization_challenge/seg_train\"\n",
        "test_dir = \"klimb_llm_optimization_challenge/seg_test\""
      ],
      "metadata": {
        "id": "vdUpb7gCvYK7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 150\n",
        "img_width = 150"
      ],
      "metadata": {
        "id": "DpeUgAervhIq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "\ttrain_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zum30QDvoEW",
        "outputId": "b97572c3-50df-42ca-f91b-4ba50e58225d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14034 files belonging to 6 classes.\n",
            "Using 11228 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iZfjw-tvupb",
        "outputId": "287be4ae-4ec5-4505-a613-68d62fb42dc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 6 classes.\n",
            "Using 600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.ResNet152(\n",
        "\t\tweights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "\t\tinput_shape=(img_height, img_width, 3),\n",
        "\t\tinclude_top=False)  # Do not include the ImageNet classifier at the top.\n",
        "base_model.trainable = False\n",
        "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning.\n",
        "x = base_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQfr10zqvxms",
        "outputId": "ed5ca8f7-f3ce-44fc-e9ea-912a0c552209"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234698864/234698864 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wUyNI8av4AZ",
        "outputId": "bca116b7-0980-4d97-9bf6-af9970480ffb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " resnet152 (Functional)      (None, 5, 5, 2048)        58370944  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 12294     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58383238 (222.71 MB)\n",
            "Trainable params: 12294 (48.02 KB)\n",
            "Non-trainable params: 58370944 (222.67 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "\t\toptimizer=keras.optimizers.Adam(),\n",
        "\t\tloss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "\t\tmetrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ],
      "metadata": {
        "id": "LdS2rnmjv77X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "model.fit(train_ds, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQyAdBEav_Aa",
        "outputId": "762cf7c3-c547-4dff-bd2b-7d550d0e6be0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "351/351 [==============================] - 59s 135ms/step - loss: 0.4092 - sparse_categorical_accuracy: 0.8578\n",
            "Epoch 2/20\n",
            "351/351 [==============================] - 50s 141ms/step - loss: 0.2517 - sparse_categorical_accuracy: 0.9113\n",
            "Epoch 3/20\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 0.2147 - sparse_categorical_accuracy: 0.9274\n",
            "Epoch 4/20\n",
            "351/351 [==============================] - 51s 143ms/step - loss: 0.1832 - sparse_categorical_accuracy: 0.9340\n",
            "Epoch 5/20\n",
            "351/351 [==============================] - 49s 139ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9428\n",
            "Epoch 6/20\n",
            "351/351 [==============================] - 50s 142ms/step - loss: 0.1450 - sparse_categorical_accuracy: 0.9479\n",
            "Epoch 7/20\n",
            "351/351 [==============================] - 50s 143ms/step - loss: 0.1292 - sparse_categorical_accuracy: 0.9551\n",
            "Epoch 8/20\n",
            "351/351 [==============================] - 50s 143ms/step - loss: 0.1181 - sparse_categorical_accuracy: 0.9605\n",
            "Epoch 9/20\n",
            "351/351 [==============================] - 50s 142ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9659\n",
            "Epoch 10/20\n",
            "351/351 [==============================] - 50s 142ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9662\n",
            "Epoch 11/20\n",
            "351/351 [==============================] - 50s 141ms/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9687\n",
            "Epoch 12/20\n",
            "351/351 [==============================] - 51s 144ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 13/20\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 14/20\n",
            "351/351 [==============================] - 50s 142ms/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9755\n",
            "Epoch 15/20\n",
            "351/351 [==============================] - 50s 143ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9766\n",
            "Epoch 16/20\n",
            "351/351 [==============================] - 49s 139ms/step - loss: 0.0673 - sparse_categorical_accuracy: 0.9792\n",
            "Epoch 17/20\n",
            "351/351 [==============================] - 50s 141ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9782\n",
            "Epoch 18/20\n",
            "351/351 [==============================] - 50s 142ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9809\n",
            "Epoch 19/20\n",
            "351/351 [==============================] - 51s 144ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9824\n",
            "Epoch 20/20\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a6700d65510>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy with trained teacher model:{results[1]*100 :.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a9QJ9uKwBYm",
        "outputId": "76e19acc-f49b-449a-a3ef-aa810efa87b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 7s 212ms/step - loss: 0.3816 - sparse_categorical_accuracy: 0.8933\n",
            "Test accuracy with trained teacher model:89.33 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Student model\n",
        "inputs_student = keras.Input(shape=(img_height, img_width, 3))\n",
        "x_student = layers.Conv2D(32, (3, 3), activation='relu')(inputs_student)\n",
        "x_student = layers.MaxPooling2D((2, 2))(x_student)\n",
        "x_student = layers.Conv2D(64, (3, 3), activation='relu')(x_student)\n",
        "x_student = layers.MaxPooling2D((2, 2))(x_student)\n",
        "x_student = layers.GlobalAveragePooling2D()(x_student)\n",
        "outputs_student = layers.Dense(6)(x_student)\n",
        "student_model = keras.Model(inputs_student, outputs_student)"
      ],
      "metadata": {
        "id": "V5PwUYvk67Ve"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8epvUdL52HYO",
        "outputId": "89f95d37-ad47-4fcb-e929-5883bf06309a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 74, 74, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_4  (None, 64)                0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19782 (77.27 KB)\n",
            "Trainable params: 19782 (77.27 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transfer weights from master model to student model\n",
        "for master_layer, student_layer in zip(model.layers, student_model.layers):\n",
        "    if isinstance(master_layer, tf.keras.layers.Conv2D) and isinstance(student_layer, tf.keras.layers.Conv2D):\n",
        "        student_layer.set_weights(master_layer.get_weights())"
      ],
      "metadata": {
        "id": "GnTvGC-t2Nd4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n"
      ],
      "metadata": {
        "id": "p3dD9sjy2VLf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_student = 50\n",
        "student_model.fit(train_ds, epochs=epochs_student)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B14ferVZ7lEi",
        "outputId": "1dae58fc-cf81-4726-eb1f-d8644385f714"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "351/351 [==============================] - 8s 24ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9748\n",
            "Epoch 2/50\n",
            "351/351 [==============================] - 7s 18ms/step - loss: 0.0673 - sparse_categorical_accuracy: 0.9771\n",
            "Epoch 3/50\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9859\n",
            "Epoch 4/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9835\n",
            "Epoch 5/50\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9782\n",
            "Epoch 6/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9751\n",
            "Epoch 7/50\n",
            "351/351 [==============================] - 9s 25ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9783\n",
            "Epoch 8/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9797\n",
            "Epoch 9/50\n",
            "351/351 [==============================] - 9s 25ms/step - loss: 0.0392 - sparse_categorical_accuracy: 0.9868\n",
            "Epoch 10/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9858\n",
            "Epoch 11/50\n",
            "351/351 [==============================] - 9s 25ms/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9805\n",
            "Epoch 12/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9768\n",
            "Epoch 13/50\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9783\n",
            "Epoch 14/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9874\n",
            "Epoch 15/50\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.0430 - sparse_categorical_accuracy: 0.9868\n",
            "Epoch 16/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9771\n",
            "Epoch 17/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9841\n",
            "Epoch 18/50\n",
            "351/351 [==============================] - 8s 24ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9771\n",
            "Epoch 19/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9897\n",
            "Epoch 20/50\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9797\n",
            "Epoch 21/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0731 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 22/50\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9810\n",
            "Epoch 23/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9838\n",
            "Epoch 24/50\n",
            "351/351 [==============================] - 8s 24ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9800\n",
            "Epoch 25/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9746\n",
            "Epoch 26/50\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.0292 - sparse_categorical_accuracy: 0.9923\n",
            "Epoch 27/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9853\n",
            "Epoch 28/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9714\n",
            "Epoch 29/50\n",
            "351/351 [==============================] - 8s 21ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9733\n",
            "Epoch 30/50\n",
            "351/351 [==============================] - 7s 20ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9910\n",
            "Epoch 31/50\n",
            "351/351 [==============================] - 7s 20ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9814\n",
            "Epoch 32/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9852\n",
            "Epoch 33/50\n",
            "351/351 [==============================] - 8s 24ms/step - loss: 0.0631 - sparse_categorical_accuracy: 0.9784\n",
            "Epoch 34/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0410 - sparse_categorical_accuracy: 0.9882\n",
            "Epoch 35/50\n",
            "351/351 [==============================] - 8s 24ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9835\n",
            "Epoch 36/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0566 - sparse_categorical_accuracy: 0.9821\n",
            "Epoch 37/50\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.0310 - sparse_categorical_accuracy: 0.9903\n",
            "Epoch 38/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0452 - sparse_categorical_accuracy: 0.9866\n",
            "Epoch 39/50\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9839\n",
            "Epoch 40/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9754\n",
            "Epoch 41/50\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9787\n",
            "Epoch 42/50\n",
            "351/351 [==============================] - 7s 18ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9905\n",
            "Epoch 43/50\n",
            "351/351 [==============================] - 8s 23ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9908\n",
            "Epoch 44/50\n",
            "351/351 [==============================] - 7s 18ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9826\n",
            "Epoch 45/50\n",
            "351/351 [==============================] - 8s 22ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9745\n",
            "Epoch 46/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0276 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 47/50\n",
            "351/351 [==============================] - 9s 24ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9842\n",
            "Epoch 48/50\n",
            "351/351 [==============================] - 6s 18ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9795\n",
            "Epoch 49/50\n",
            "351/351 [==============================] - 8s 24ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9849\n",
            "Epoch 50/50\n",
            "351/351 [==============================] - 7s 19ms/step - loss: 0.0259 - sparse_categorical_accuracy: 0.9932\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a663c2fa6e0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_master = student_model.evaluate(test_ds)\n",
        "print(f\"Test accuracy with trained teacher model: {results_master[1]*100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYEy26WW7uXE",
        "outputId": "a21b05a6-dc21-4b6b-ac0d-b817b299946d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 23ms/step - loss: 1.1519 - sparse_categorical_accuracy: 0.8533\n",
            "Test accuracy with trained teacher model: 85.33 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model size and parameter ratios\n",
        "master_model_size = len(model.to_json())\n",
        "student_model_size = len(student_model.to_json())\n",
        "model_size_ratio = master_model_size / student_model_size\n",
        "\n",
        "master_model_params = model.count_params()\n",
        "student_model_params = student_model.count_params()\n",
        "param_ratio = master_model_params / student_model_params"
      ],
      "metadata": {
        "id": "YXtKENbiEry7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display ratios\n",
        "print(f\"Model Size Ratio (Master/Student): {model_size_ratio:.2f}\")\n",
        "print(f\"Parameter Ratio (Master/Student): {param_ratio:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv_BL0oOE1VI",
        "outputId": "4d85b403-8633-4344-8260-f6f6ff2ceb09"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size Ratio (Master/Student): 89.30\n",
            "Parameter Ratio (Master/Student): 2951.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Function to measure latency for model predictions\n",
        "def measure_latency(model, dataset):\n",
        "    start_time = time.time()\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        _ = model.predict(images)  # Assuming a single prediction for simplicity\n",
        "\n",
        "    end_time = time.time()\n",
        "    latency = (end_time - start_time) / len(dataset)\n",
        "\n",
        "    return latency\n"
      ],
      "metadata": {
        "id": "xPl72XbXE3ZZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure latency for the master model\n",
        "master_latency = measure_latency(model, test_ds)\n",
        "print(f\"Latency for Master Model: {master_latency:.4f} seconds per prediction\")\n",
        "\n",
        "# Measure latency for the student model\n",
        "student_latency = measure_latency(student_model, test_ds)\n",
        "print(f\"Latency for Student Model: {student_latency:.4f} seconds per prediction\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sghh78c_FE9g",
        "outputId": "1b0c3620-b6ee-445f-ccb0-a44edd6fb05e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Latency for Master Model: 0.5462 seconds per prediction\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Latency for Student Model: 0.0756 seconds per prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End-to-End Functionality: The entire pipeline, from the model building to the final prediction\n",
        "# from both master and student models should be operational without any errors.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Function to load data\n",
        "def load_data(train_dir, test_dir, img_height, img_width, batch_size):\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=(img_height, img_width),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    return train_ds, test_ds\n",
        "\n",
        "# Define the master model\n",
        "def build_master_model(img_height, img_width):\n",
        "    base_model = keras.applications.ResNet152(\n",
        "        weights='imagenet',\n",
        "        input_shape=(img_height, img_width, 3),\n",
        "        include_top=False\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs_master = keras.Input(shape=(img_height, img_width, 3))\n",
        "    x_master = base_model(inputs_master, training=False)\n",
        "    x_master = keras.layers.GlobalAveragePooling2D()(x_master)\n",
        "    outputs_master = keras.layers.Dense(6)(x_master)\n",
        "    master_model = keras.Model(inputs_master, outputs_master)\n",
        "\n",
        "    return master_model\n",
        "\n",
        "# Define the student model\n",
        "def build_student_model(img_height, img_width):\n",
        "    inputs_student = keras.Input(shape=(img_height, img_width, 3))\n",
        "    x_student = layers.Conv2D(32, (3, 3), activation='relu')(inputs_student)\n",
        "    x_student = layers.MaxPooling2D((2, 2))(x_student)\n",
        "    x_student = layers.Conv2D(64, (3, 3), activation='relu')(x_student)\n",
        "    x_student = layers.MaxPooling2D((2, 2))(x_student)\n",
        "    x_student = layers.GlobalAveragePooling2D()(x_student)\n",
        "    outputs_student = layers.Dense(6)(x_student)\n",
        "    student_model = keras.Model(inputs_student, outputs_student)\n",
        "\n",
        "    return student_model\n",
        "\n",
        "# Function to transfer weights from master to student model\n",
        "def transfer_weights(master_model, student_model):\n",
        "    for master_layer, student_layer in zip(master_model.layers, student_model.layers):\n",
        "        if isinstance(master_layer, tf.keras.layers.Conv2D) and isinstance(student_layer, tf.keras.layers.Conv2D):\n",
        "            student_layer.set_weights(master_layer.get_weights())\n",
        "\n",
        "# Function to train and evaluate models\n",
        "def train_and_evaluate_models(train_ds, test_ds, master_model, student_model, epochs):\n",
        "    # Compile master model\n",
        "    master_model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "\n",
        "    # Train master model\n",
        "    master_model.fit(train_ds, epochs=epochs)\n",
        "\n",
        "    # Compile student model\n",
        "    student_model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "\n",
        "    # Transfer weights from master to student model\n",
        "    transfer_weights(master_model, student_model)\n",
        "\n",
        "    # Train student model\n",
        "    student_model.fit(train_ds, epochs=epochs)\n",
        "\n",
        "    # Evaluate models on test data\n",
        "    results_master = master_model.evaluate(test_ds)\n",
        "    print(f\"Test accuracy with trained master model: {results_master[1]*100:.2f} %\")\n",
        "\n",
        "    results_student = student_model.evaluate(test_ds)\n",
        "    print(f\"Test accuracy with trained student model: {results_student[1]*100:.2f} %\")\n",
        "\n",
        "# Set up parameters\n",
        "img_height = 150\n",
        "img_width = 150\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "train_dir = \"klimb_llm_optimization_challenge/seg_train\"\n",
        "test_dir = \"klimb_llm_optimization_challenge/seg_test\"\n",
        "\n",
        "# Load data\n",
        "train_ds, test_ds = load_data(train_dir, test_dir, img_height, img_width, batch_size)\n",
        "\n",
        "# Build models\n",
        "master_model = build_master_model(img_height, img_width)\n",
        "student_model = build_student_model(img_height, img_width)\n",
        "\n",
        "# Train and evaluate models\n",
        "train_and_evaluate_models(train_ds, test_ds, master_model, student_model, epochs)\n"
      ],
      "metadata": {
        "id": "DiNzUsbSFHU5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}